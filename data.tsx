import React from 'react';
import { Chapter, Language } from './types';
import MathBlock from './components/MathBlock';
import InteractiveAttention from './components/InteractiveAttention';
import ArchitectureDiagram from './components/ArchitectureDiagram';
import { BarChart, Bar, XAxis, YAxis, CartesianGrid, Tooltip, Legend, ResponsiveContainer } from 'recharts';

// Helper for code blocks
const Code = ({ code }: { code: string }) => (
  <div className="my-4">
    <div className="bg-slate-800 text-slate-300 px-4 py-2 text-xs rounded-t-lg font-mono border-b border-slate-700">
      PyTorch Implementation / Pseudo-code
    </div>
    <pre className="bg-slate-900 text-blue-100 p-4 rounded-b-lg overflow-x-auto text-sm font-mono leading-relaxed shadow-inner">
      <code>{code}</code>
    </pre>
  </div>
);

const perfData = [
  { name: 'ByteNet', bleu: 23.7, speed: 10 },
  { name: 'Deep-Att', bleu: 24.6, speed: 20 },
  { name: 'GNMT', bleu: 24.6, speed: 50 },
  { name: 'Transformer (Base)', bleu: 27.3, speed: 90 },
  { name: 'Transformer (Big)', bleu: 28.4, speed: 80 },
];

export const uiTranslations = {
  en: {
    home: "Home",
    curriculum: "Curriculum",
    start: "Start Learning",
    paper: "Read Paper",
    prev: "Previous",
    next: "Next",
    title: "Transformer Explained",
    subtitle: "Transformer Decoded",
    desc: "A comprehensive, interactive deep dive into the architecture that revolutionized Natural Language Processing. Based on the paper \"Attention Is All You Need\".",
    whyTitle: "Why this matters",
    whyDesc: "The Transformer abandoned the recurrence of RNNs and introduced a purely attention-based architecture. This shift enabled massive parallelization, paving the way for models like BERT, GPT-4, and Gemini.",
    stats: { published: "Published", citations: "Citations", concept: "Key Concept" }
  },
  zh: {
    home: "é¦–é¡µ",
    curriculum: "è¯¾ç¨‹å¤§çº²",
    start: "å¼€å§‹å­¦ä¹ ",
    paper: "é˜…è¯»è®ºæ–‡",
    prev: "ä¸Šä¸€ç« ",
    next: "ä¸‹ä¸€ç« ",
    title: "Transformer è¯¦è§£",
    subtitle: "Transformer è§£å¯†",
    desc: "æ·±å…¥æµ…å‡ºåœ°è§£ææ”¹å˜è‡ªç„¶è¯­è¨€å¤„ç†æ ¼å±€çš„ Transformer æ¶æ„ã€‚åŸºäºè®ºæ–‡ã€ŠAttention Is All You Needã€‹ã€‚",
    whyTitle: "æ ¸å¿ƒæ„ä¹‰",
    whyDesc: "Transformer æ‘’å¼ƒäº† RNN çš„å¾ªç¯ç»“æ„ï¼Œå¼•å…¥äº†çº¯ç²¹çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™ä¸€è½¬å˜ä¸º BERTã€GPT-4 å’Œ Gemini ç­‰æ¨¡å‹çš„å¤§è§„æ¨¡å¹¶è¡ŒåŒ–é“ºå¹³äº†é“è·¯ã€‚",
    stats: { published: "å‘å¸ƒäº", citations: "å¼•ç”¨æ¬¡æ•°", concept: "æ ¸å¿ƒæ¦‚å¿µ" }
  }
};

const chaptersEn: Chapter[] = [
  {
    id: 'ch1',
    title: '1. Background & Motivation',
    description: 'Why do we need the Transformer?',
    sections: [
      {
        id: '1-1',
        title: 'Pain Points of Recurrent Models',
        content: (
          <div>
            <p className="mb-4">
              Before 2017, sequence modeling (like translation) was dominated by RNNs and LSTMs.
              These models process data <strong>sequentially</strong>.
            </p>
            <ul className="list-disc ml-6 space-y-2 mb-4">
              <li><strong>Sequential Computation:</strong> To compute hidden state <MathBlock formula="h_t" />, you need <MathBlock formula="h_{t-1}" />. This precludes parallelization.</li>
              <li><strong>Long-Term Dependencies:</strong> Information from the beginning of a long sentence often fades before reaching the end.</li>
            </ul>
            <div className="bg-red-50 border-l-4 border-red-500 p-4">
              <strong>The Goal:</strong> Create a model that is highly parallelizable and can relate any two positions in a sequence instantly.
            </div>
          </div>
        )
      },
      {
        id: '1-2',
        title: 'Attention is All You Need',
        content: (
          <div>
            <p className="mb-4">
              The paper proposes that we don't need recurrence (RNNs) or convolution (CNNs). Instead, we can rely entirely on an <strong>Attention Mechanism</strong> to draw global dependencies between input and output.
            </p>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch2',
    title: '2. Architecture Overview',
    description: 'The High-Level Encoder-Decoder Structure',
    sections: [
      {
        id: '2-1',
        title: 'The Big Picture',
        content: (
          <div>
            <p className="mb-4">
              The Transformer follows an Encoder-Decoder architecture.
            </p>
            <ArchitectureDiagram lang="en" />
            <div className="grid md:grid-cols-2 gap-4">
              <div className="bg-white p-4 rounded shadow-sm border">
                <h4 className="font-bold text-brand-600 mb-2">Encoder (Left)</h4>
                <p className="text-sm">Takes the input sequence (e.g., English sentence) and maps it to a continuous representation holding the meaning.</p>
              </div>
              <div className="bg-white p-4 rounded shadow-sm border">
                <h4 className="font-bold text-pink-600 mb-2">Decoder (Right)</h4>
                <p className="text-sm">Takes the Encoder's output and generates the target sequence (e.g., French translation) one element at a time.</p>
              </div>
            </div>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch3',
    title: '3. Core Components (Deep Dive)',
    description: 'Understanding the mechanics',
    sections: [
      {
        id: '3-1',
        title: 'Self-Attention',
        difficulty: 'advanced',
        content: (
          <div>
            <p className="mb-4">
              The heart of the Transformer. It allows the model to look at other words in the input sentence to better understand the current word.
            </p>
            <div className="bg-blue-50 p-4 rounded-lg mb-4 border border-blue-100">
                <h4 className="font-bold text-blue-800 mb-2">Example:</h4>
                <p className="italic text-slate-700">"The animal didn't cross the street because <strong>it</strong> was too tired."</p>
                <p className="mt-2 text-sm">
                    When the model processes the word "it", Self-Attention allows it to associate "it" strongly with "animal". 
                    Without this, the model wouldn't know if "it" referred to the street or the animal.
                </p>
            </div>
            <p className="mb-4">
              For every input token, we create three vectors: 
              <strong>Query ($Q$)</strong>, <strong>Key ($K$)</strong>, and <strong>Value ($V$)</strong>.
            </p>
            <MathBlock formula="\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V" block />
            
            <Code code={`# PyTorch-like Pseudo-code
def scaled_dot_product_attention(query, key, value):
    d_k = query.size(-1)
    
    # 1. Calculate Scores (How much to focus)
    scores = torch.matmul(query, key.transpose(-2, -1))
    
    # 2. Scale (Stability)
    scores = scores / math.sqrt(d_k)
    
    # 3. Probability (0 to 1)
    weights = F.softmax(scores, dim=-1)
    
    # 4. Weighted Sum
    output = torch.matmul(weights, value)
    return output`} />

            <InteractiveAttention lang="en" />
          </div>
        )
      },
      {
        id: '3-2',
        title: 'Multi-Head Attention',
        content: (
          <div>
            <p className="mb-4">
              Instead of performing a single attention function, we do it $h$ times in parallel with different linear projections. This allows the model to attend to information from different representation subspaces.
            </p>
            <div className="p-4 bg-brand-50 rounded-lg text-sm text-brand-900 mb-4">
              <strong>Analogy:</strong> Imagine reading a book with 8 different colored highlighters. 
              The "Yellow" head focuses on dates, the "Blue" head focuses on names, and the "Green" head focuses on actions.
              Combining them gives you a complete understanding.
            </div>
            <Code code={`class MultiHeadAttention(nn.Module):
    def forward(self, x):
        # Split input into 'h' heads
        # ... (splitting logic)
        
        # Apply attention to each head independently
        head_outputs = [attention(q, k, v) for q,k,v in heads]
        
        # Concatenate results and pass through linear layer
        concat = torch.cat(head_outputs, dim=-1)
        return self.final_linear(concat)`} />
          </div>
        )
      },
      {
        id: '3-3',
        title: 'Positional Encoding',
        difficulty: 'intermediate',
        content: (
          <div>
            <p className="mb-4">
              Since the Transformer has no recurrence, it has no notion of "order". We must inject position info directly into the embeddings.
            </p>
            <div className="bg-yellow-50 p-4 rounded-lg mb-4 border border-yellow-100">
                <h4 className="font-bold text-yellow-800 mb-2">Analogy:</h4>
                <p className="text-sm">
                    Imagine a library where books are thrown in a pile (Bag of Words). You don't know the story order.
                    Positional Encoding is like stamping a page number on each word so the model knows where it belongs, 
                    even if processed simultaneously.
                </p>
            </div>
            <MathBlock formula="PE_{(pos, 2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}})" block />
            <MathBlock formula="PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i/d_{\\text{model}}})" block />
            <Code code={`# Adding position info to embeddings
position = torch.arange(max_len).unsqueeze(1)
div_term = torch.exp(torch.arange(0, d_model, 2) * ...)

pe[:, 0::2] = torch.sin(position * div_term)
pe[:, 1::2] = torch.cos(position * div_term)

# Add directly to input embeddings
x = embeddings(input) + pe`} />
          </div>
        )
      }
    ]
  },
  {
    id: 'ch4',
    title: '4. Training & Details',
    description: 'How to make it learn',
    sections: [
      {
        id: '4-1',
        title: 'Masking',
        content: (
          <div>
            <h3 className="font-bold text-lg mb-2">Technical Explanation</h3>
            <p className="mb-4">
              <strong>Padding Mask:</strong> Ignores padding tokens (usually index 0) so they don't affect gradients.
              <br/>
              <strong>Look-Ahead Mask:</strong> Used in the decoder. When predicting token at $t$, it masks tokens at $t+1$ and beyond by setting their attention scores to $-\infty$.
            </p>
            
            <div className="bg-slate-100 p-4 rounded-lg border-l-4 border-slate-400">
                <h4 className="font-bold mb-1">Layman's Understanding</h4>
                <p className="text-sm">
                    Imagine taking a test. You want to learn to predict the next word.
                    If you can see the future words (the answers) while guessing the current one, you aren't learning.
                    <strong>Look-Ahead Masking</strong> is like covering the rest of the sentence with a piece of paper so you can only see what you've written so far.
                </p>
            </div>
          </div>
        )
      },
      {
        id: '4-2',
        title: 'Optimizer & Regularization',
        content: (
          <div>
            <h3 className="font-bold text-lg mb-2">Technical Explanation</h3>
            <p className="mb-4">
              Uses the <strong>Adam</strong> optimizer with custom $\beta$ parameters.
              Crucially, it uses a <strong>Learning Rate Schedule</strong> with a "warmup" phase.
              Regularization includes <strong>Residual Connections</strong> (Skip connections) and <strong>Layer Normalization</strong>.
            </p>
            
            <div className="bg-slate-100 p-4 rounded-lg border-l-4 border-slate-400">
                <h4 className="font-bold mb-1">Layman's Understanding</h4>
                <p className="text-sm mb-2">
                    <strong>Warmup:</strong> It's like a sprinter starting a race. You don't go full speed immediately; you accelerate smoothly to avoid stumbling (diverging gradients), then settle into a pace.
                </p>
                <p className="text-sm">
                   <strong>Residual Connections:</strong> Like having a "direct highway" for information to flow through the network, preventing it from getting lost in the complex "traffic" of the layers.
                </p>
            </div>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch5',
    title: '5. Experimental Results',
    description: 'Does it actually work?',
    sections: [
      {
        id: '5-1',
        title: 'Performance & Efficiency',
        content: (
          <div>
            <p className="mb-4">
                The Transformer achieved state-of-the-art results on English-to-German and English-to-French translation tasks (WMT 2014), while requiring significantly less training time than RNN/CNN based predecessors.
            </p>
            <div className="h-64 w-full mb-6">
              <ResponsiveContainer width="100%" height="100%">
                <BarChart data={perfData} layout="vertical" margin={{ top: 5, right: 30, left: 40, bottom: 5 }}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis type="number" domain={[20, 30]} />
                  <YAxis dataKey="name" type="category" width={100} style={{fontSize: '12px'}} />
                  <Tooltip />
                  <Legend />
                  <Bar dataKey="bleu" name="BLEU Score" fill="#0ea5e9" />
                </BarChart>
              </ResponsiveContainer>
              <p className="text-center text-xs text-slate-500 mt-2">Comparison of BLEU scores (Higher is better)</p>
            </div>
            
            <div className="grid grid-cols-2 gap-4">
                <div className="p-4 border rounded bg-white">
                    <h4 className="font-bold text-green-600">Training Efficiency</h4>
                    <p className="text-sm mt-1">
                        Because of parallelization, the Transformer (Big) trained in just <strong>3.5 days</strong> on 8 GPUs, whereas previous best models took weeks.
                    </p>
                </div>
                <div className="p-4 border rounded bg-white">
                    <h4 className="font-bold text-purple-600">Generalization</h4>
                    <p className="text-sm mt-1">
                        The paper demonstrated the model generalizes well to other tasks like Constituency Parsing with minimal tuning.
                    </p>
                </div>
            </div>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch6',
    title: '6. Resources',
    description: 'Further exploration',
    sections: [
      {
        id: '6-1',
        title: 'Official Implementations',
        content: (
          <div>
            <p className="mb-4">
                The original code was released in the Tensor2Tensor library. Below are the links to the original implementations and the paper.
            </p>
            <ul className="space-y-4">
                <li>
                    <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noreferrer" className="flex items-center gap-2 p-4 border rounded hover:bg-slate-50 transition group">
                        <span className="text-2xl">ğŸ“„</span>
                        <div>
                            <div className="font-bold text-brand-600 group-hover:underline">Original Paper (ArXiv)</div>
                            <div className="text-sm text-slate-500">Attention Is All You Need (Vaswani et al., 2017)</div>
                        </div>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noreferrer" className="flex items-center gap-2 p-4 border rounded hover:bg-slate-50 transition group">
                        <span className="text-2xl">ğŸ’»</span>
                        <div>
                            <div className="font-bold text-slate-800 group-hover:underline">Tensor2Tensor (Original Code)</div>
                            <div className="text-sm text-slate-500">The official TensorFlow implementation used in the paper.</div>
                        </div>
                    </a>
                </li>
                 <li>
                    <a href="https://github.com/pytorch/fairseq" target="_blank" rel="noreferrer" className="flex items-center gap-2 p-4 border rounded hover:bg-slate-50 transition group">
                        <span className="text-2xl">ğŸ”¥</span>
                        <div>
                            <div className="font-bold text-slate-800 group-hover:underline">PyTorch FairSeq</div>
                            <div className="text-sm text-slate-500">Facebook AI Research Sequence-to-Sequence Toolkit.</div>
                        </div>
                    </a>
                </li>
            </ul>
          </div>
        )
      }
    ]
  }
];

const chaptersZh: Chapter[] = [
  {
    id: 'ch1',
    title: '1. èƒŒæ™¯ä¸åŠ¨æœº',
    description: 'ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ Transformerï¼Ÿ',
    sections: [
      {
        id: '1-1',
        title: 'ä¼ ç»Ÿæ¨¡å‹çš„ç—›ç‚¹',
        content: (
          <div>
            <p className="mb-4">
              åœ¨2017å¹´ä¹‹å‰ï¼Œåºåˆ—å»ºæ¨¡ï¼ˆå¦‚æœºå™¨ç¿»è¯‘ï¼‰ä¸»è¦ç”± RNN å’Œ LSTM ä¸»å¯¼ã€‚
              è¿™äº›æ¨¡å‹ä»¥<strong>ä¸²è¡Œæ–¹å¼</strong>å¤„ç†æ•°æ®ã€‚
            </p>
            <ul className="list-disc ml-6 space-y-2 mb-4">
              <li><strong>ä¸²è¡Œè®¡ç®—ï¼š</strong> è®¡ç®—éšè—çŠ¶æ€ <MathBlock formula="h_t" /> å¿…é¡»ä¾èµ– <MathBlock formula="h_{t-1}" />ã€‚è¿™ä½¿å¾—æ— æ³•è¿›è¡Œå¹¶è¡Œè®¡ç®—ã€‚</li>
              <li><strong>é•¿è·ç¦»ä¾èµ–ï¼š</strong> åœ¨å¤„ç†é•¿å¥å­æ—¶ï¼Œå¼€å¤´çš„ä¿¡æ¯å¾€å¾€åœ¨åˆ°è¾¾å¥å­æœ«å°¾æ—¶å·²ç»ä¸¢å¤±ã€‚</li>
            </ul>
            <div className="bg-red-50 border-l-4 border-red-500 p-4">
              <strong>ç›®æ ‡ï¼š</strong> åˆ›å»ºä¸€ä¸ªé«˜åº¦å¹¶è¡ŒåŒ–çš„æ¨¡å‹ï¼Œå¹¶èƒ½ç¬é—´å»ºç«‹åºåˆ—ä¸­ä»»æ„ä¸¤ä¸ªä½ç½®çš„è”ç³»ã€‚
            </div>
          </div>
        )
      },
      {
        id: '1-2',
        title: 'Attention Is All You Need',
        content: (
          <div>
            <p className="mb-4">
              è®ºæ–‡æå‡ºæˆ‘ä»¬ä¸å†éœ€è¦å¾ªç¯ï¼ˆRNNï¼‰æˆ–å·ç§¯ï¼ˆCNNï¼‰ã€‚ç›¸åï¼Œæˆ‘ä»¬å¯ä»¥å®Œå…¨ä¾èµ–<strong>æ³¨æ„åŠ›æœºåˆ¶ (Attention Mechanism)</strong> æ¥æ•æ‰è¾“å…¥ä¸è¾“å‡ºä¹‹é—´çš„å…¨å±€ä¾èµ–å…³ç³»ã€‚
            </p>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch2',
    title: '2. æ•´ä½“æ¶æ„æ¦‚è§ˆ',
    description: 'å®è§‚è§†è§’çš„ç¼–ç å™¨-è§£ç å™¨ç»“æ„',
    sections: [
      {
        id: '2-1',
        title: 'å…¨æ™¯å›¾',
        content: (
          <div>
            <p className="mb-4">
              Transformer éµå¾ªç¼–ç å™¨-è§£ç å™¨ (Encoder-Decoder) æ¶æ„ã€‚
            </p>
            <ArchitectureDiagram lang="zh" />
            <div className="grid md:grid-cols-2 gap-4">
              <div className="bg-white p-4 rounded shadow-sm border">
                <h4 className="font-bold text-brand-600 mb-2">Encoder (ç¼–ç å™¨ - å·¦ä¾§)</h4>
                <p className="text-sm">æ¥æ”¶è¾“å…¥åºåˆ—ï¼ˆä¾‹å¦‚ï¼šè‹±æ–‡å¥å­ï¼‰å¹¶å°†å…¶æ˜ å°„ä¸ºåŒ…å«è¯­ä¹‰ä¿¡æ¯çš„è¿ç»­è¡¨ç¤ºã€‚</p>
              </div>
              <div className="bg-white p-4 rounded shadow-sm border">
                <h4 className="font-bold text-pink-600 mb-2">Decoder (è§£ç å™¨ - å³ä¾§)</h4>
                <p className="text-sm">æ¥æ”¶ç¼–ç å™¨çš„è¾“å‡ºï¼Œå¹¶é€ä¸ªå…ƒç´ ç”Ÿæˆç›®æ ‡åºåˆ—ï¼ˆä¾‹å¦‚ï¼šæ³•æ–‡ç¿»è¯‘ï¼‰ã€‚</p>
              </div>
            </div>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch3',
    title: '3. æ ¸å¿ƒç»„ä»¶è¯¦è§£',
    description: 'æ·±å…¥å‰–æå†…éƒ¨æœºåˆ¶',
    sections: [
      {
        id: '3-1',
        title: 'è‡ªæ³¨æ„åŠ›æœºåˆ¶ (Self-Attention)',
        difficulty: 'advanced',
        content: (
          <div>
            <p className="mb-4">
              è¿™æ˜¯ Transformer çš„æ ¸å¿ƒã€‚å®ƒå…è®¸æ¨¡å‹åœ¨å¤„ç†å½“å‰è¯æ—¶ï¼Œå…³æ³¨è¾“å…¥å¥å­ä¸­çš„å…¶ä»–è¯ï¼Œä»è€Œæ›´å¥½åœ°ç†è§£ä¸Šä¸‹æ–‡ã€‚
            </p>
            <div className="bg-blue-50 p-4 rounded-lg mb-4 border border-blue-100">
                <h4 className="font-bold text-blue-800 mb-2">ä¸¾ä¸ªæ —å­ï¼š</h4>
                <p className="italic text-slate-700">"The animal didn't cross the street because <strong>it</strong> was too tired."</p>
                <p className="mt-2 text-sm">
                    å½“æ¨¡å‹å¤„ç† "it"ï¼ˆå®ƒï¼‰è¿™ä¸ªè¯æ—¶ï¼Œè‡ªæ³¨æ„åŠ›æœºåˆ¶ä¼šå°†å®ƒä¸ "animal"ï¼ˆåŠ¨ç‰©ï¼‰å¼ºçƒˆå…³è”èµ·æ¥ã€‚
                    å¦‚æœæ²¡æœ‰è¿™ä¸ªæœºåˆ¶ï¼Œæœºå™¨å¯èƒ½ä¸çŸ¥é“ "it" æŒ‡çš„æ˜¯è¡—é“è¿˜æ˜¯åŠ¨ç‰©ã€‚
                </p>
            </div>

            <p className="mb-4">
              å¯¹äºæ¯ä¸ªè¾“å…¥ Tokenï¼Œæˆ‘ä»¬åˆ›å»ºä¸‰ä¸ªå‘é‡ï¼š
              <strong>Query ($Q$, æŸ¥è¯¢)</strong>, <strong>Key ($K$, é”®)</strong>, å’Œ <strong>Value ($V$, å€¼)</strong>ã€‚
            </p>
            <MathBlock formula="\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V" block />
            
            <Code code={`# PyTorch é£æ ¼ä¼ªä»£ç 
def scaled_dot_product_attention(query, key, value):
    d_k = query.size(-1)
    
    # 1. è®¡ç®—åˆ†æ•° (å…³æ³¨åº¦) - ä¸¤ä¸ªå‘é‡è¶Šç›¸ä¼¼ï¼Œç‚¹ç§¯è¶Šå¤§
    scores = torch.matmul(query, key.transpose(-2, -1))
    
    # 2. ç¼©æ”¾ (ä¿æŒæ¢¯åº¦ç¨³å®š)
    scores = scores / math.sqrt(d_k)
    
    # 3. æ¦‚ç‡å½’ä¸€åŒ– (Softmax ä¿è¯å’Œä¸º 1)
    weights = F.softmax(scores, dim=-1)
    
    # 4. åŠ æƒæ±‚å’Œ (æå–ä¿¡æ¯)
    output = torch.matmul(weights, value)
    return output`} />

            <InteractiveAttention lang="zh" />
          </div>
        )
      },
      {
        id: '3-2',
        title: 'å¤šå¤´æ³¨æ„åŠ› (Multi-Head Attention)',
        content: (
          <div>
            <p className="mb-4">
              æ¨¡å‹ä¸æ˜¯åªæ‰§è¡Œä¸€æ¬¡æ³¨æ„åŠ›å‡½æ•°ï¼Œè€Œæ˜¯å¹¶è¡Œæ‰§è¡Œ $h$ æ¬¡ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„çº¿æ€§æŠ•å½±ã€‚è¿™å…è®¸æ¨¡å‹å…³æ³¨ä¸åŒè¡¨ç¤ºå­ç©ºé—´çš„ä¿¡æ¯ã€‚
            </p>
            <div className="p-4 bg-brand-50 rounded-lg text-sm text-brand-900 mb-4">
              <strong>é€šä¿—ç†è§£ï¼š</strong> å°±åƒçœ‹ä¹¦æ—¶ä½¿ç”¨ 8 ç§ä¸åŒé¢œè‰²çš„è§å…‰ç¬”ã€‚
              é»„è‰²ç¬”æ ‡è®°â€œæ—¶é—´â€ï¼Œè“è‰²ç¬”æ ‡è®°â€œäººç‰©â€ï¼Œç»¿è‰²ç¬”æ ‡è®°â€œåŠ¨ä½œâ€ã€‚
              æœ€åæŠŠæ‰€æœ‰æ ‡è®°çš„ä¿¡æ¯æ±‡æ€»ï¼Œä½ å°±å¾—åˆ°äº†æœ€å…¨é¢çš„ç†è§£ã€‚å¦‚æœåªæœ‰ä¸€ç§é¢œè‰²ï¼Œä¿¡æ¯å¯èƒ½ä¼šæ··æ‚ã€‚
            </div>
             <Code code={`class MultiHeadAttention(nn.Module):
    def forward(self, x):
        # å°†è¾“å…¥åˆ†å‰²æˆ h ä¸ªå¤´ (Heads)
        # ... (split logic)
        
        # æ¯ä¸ªå¤´ç‹¬ç«‹è¿›è¡Œæ³¨æ„åŠ›è®¡ç®—
        head_outputs = [attention(q, k, v) for q,k,v in heads]
        
        # æ‹¼æ¥æ‰€æœ‰å¤´çš„ç»“æœå¹¶é€šè¿‡çº¿æ€§å±‚èåˆ
        concat = torch.cat(head_outputs, dim=-1)
        return self.final_linear(concat)`} />
          </div>
        )
      },
      {
        id: '3-3',
        title: 'ä½ç½®ç¼–ç  (Positional Encoding)',
        difficulty: 'intermediate',
        content: (
          <div>
             <p className="mb-4">
              ç”±äº Transformer æ²¡æœ‰å¾ªç¯ç»“æ„ï¼Œå®ƒæœ¬èº«ä¸çŸ¥é“å•è¯çš„é¡ºåºã€‚æˆ‘ä»¬å¿…é¡»å°†ä½ç½®ä¿¡æ¯æ³¨å…¥åˆ° Embedding ä¸­ã€‚
            </p>
             <div className="bg-yellow-50 p-4 rounded-lg mb-4 border border-yellow-100">
                <h4 className="font-bold text-yellow-800 mb-2">é€šä¿—ç†è§£ï¼š</h4>
                <p className="text-sm">
                    æƒ³è±¡å›¾ä¹¦é¦†æŠŠä¸€æœ¬ä¹¦æ‹†æ•£æˆä¸€å †çº¸ï¼ˆBag of Wordsï¼‰ï¼Œé¡ºåºå…¨ä¹±äº†ã€‚
                    ä½ç½®ç¼–ç å°±åƒæ˜¯åœ¨æ¯ä¸€é¡µçº¸çš„é¡µè„šæ‰“ä¸Šé¡µç ã€‚è¿™æ ·å³ä½¿ä½ åŒæ—¶å¤„ç†æ‰€æœ‰çº¸å¼ ï¼Œä½ ä¹ŸçŸ¥é“å“ªä¸€é¡µåœ¨å‰ï¼Œå“ªä¸€é¡µåœ¨åã€‚
                </p>
            </div>
            <p className="mb-4">
              æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ä¸åŒé¢‘ç‡çš„æ­£å¼¦å’Œä½™å¼¦å‡½æ•°ï¼Œå°†ä½ç½®å‘é‡æ·»åŠ åˆ°è¾“å…¥åµŒå…¥ä¸­ã€‚
            </p>
            <MathBlock formula="PE_{(pos, 2i)} = \\sin(pos / 10000^{2i/d_{\\text{model}}})" block />
            <MathBlock formula="PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i/d_{\\text{model}}})" block />
            <Code code={`# ç”Ÿæˆä½ç½®ç¼–ç å¹¶åŠ åˆ° Input Embedding ä¸Š
position = torch.arange(max_len).unsqueeze(1)
div_term = torch.exp(torch.arange(0, d_model, 2) * ...)

pe[:, 0::2] = torch.sin(position * div_term)
pe[:, 1::2] = torch.cos(position * div_term)

# ç›´æ¥ç›¸åŠ ï¼Œä¸æ”¹å˜ç»´åº¦
x = embeddings(input) + pe`} />
          </div>
        )
      }
    ]
  },
  {
    id: 'ch4',
    title: '4. è®­ç»ƒä¸ç»†èŠ‚',
    description: 'å¦‚ä½•è®©æ¨¡å‹å­¦ä¹ ',
    sections: [
      {
        id: '4-1',
        title: 'æ©ç  (Masking)',
        content: (
          <div>
            <h3 className="font-bold text-lg mb-2">æŠ€æœ¯è§£é‡Š</h3>
            <p className="mb-4">
              <strong>å¡«å……æ©ç  (Padding Mask)ï¼š</strong> å¿½ç•¥è¾“å…¥åºåˆ—ä¸­ä¸ºäº†å¯¹é½é•¿åº¦è€Œå¡«å……çš„ 0 (Padding Tokens)ã€‚
              <br/>
              <strong>å‰ç»æ©ç  (Look-Ahead Mask)ï¼š</strong> ç”¨äºè§£ç å™¨ã€‚åœ¨é¢„æµ‹ç¬¬ $t$ ä¸ªè¯æ—¶ï¼Œå°† $t$ ä¹‹åçš„ä½ç½®çš„æ³¨æ„åŠ›åˆ†æ•°è®¾ä¸º $-\\infty$ï¼ˆè´Ÿæ— ç©·ï¼‰ã€‚
            </p>
            
            <div className="bg-slate-100 p-4 rounded-lg border-l-4 border-slate-400">
                <h4 className="font-bold mb-1">é€šä¿—ç†è§£ï¼š</h4>
                <p className="text-sm">
                    è¿™å°±å¥½æ¯”åœ¨åšè‹±è¯­å¡«ç©ºé¢˜ã€‚
                    å¦‚æœä½ åœ¨å¡«ç¬¬ 3 ä¸ªç©ºçš„æ—¶å€™ï¼Œå·çœ‹äº†ç¬¬ 4 ä¸ªç©ºçš„ç­”æ¡ˆï¼Œé‚£ä½ å°±æ²¡æœ‰çœŸæ­£å­¦ä¼šé¢„æµ‹ã€‚
                    <strong>å‰ç»æ©ç </strong>å°±åƒæ˜¯ç”¨ä¸€å¼ çº¸æŠŠåé¢çš„ç­”æ¡ˆæŒ¡ä½ï¼Œå¼ºè¿«æ¨¡å‹åªèƒ½æ ¹æ®å·²çŸ¥çš„ä¸Šæ–‡æ¥æ¨æ–­ä¸‹æ–‡ã€‚
                </p>
            </div>
          </div>
        )
      },
      {
        id: '4-2',
        title: 'ä¼˜åŒ–å™¨ä¸æ­£åˆ™åŒ–',
        content: (
          <div>
             <h3 className="font-bold text-lg mb-2">æŠ€æœ¯è§£é‡Š</h3>
            <p className="mb-4">
              ä½¿ç”¨ <strong>Adam</strong> ä¼˜åŒ–å™¨ã€‚å…³é”®åœ¨äºä½¿ç”¨äº† <strong>Warmupï¼ˆçƒ­èº«ï¼‰</strong> ç­–ç•¥ï¼šå­¦ä¹ ç‡åœ¨è®­ç»ƒåˆæœŸçº¿æ€§å¢åŠ ï¼ŒéšåæŒ‰å¹³æ–¹æ ¹å€’æ•°è¡°å‡ã€‚
              æ­¤å¤–å¹¿æ³›ä½¿ç”¨äº†æ®‹å·®è¿æ¥ (Residual Connections) å’Œå±‚å½’ä¸€åŒ– (Layer Normalization)ã€‚
            </p>
            
             <div className="bg-slate-100 p-4 rounded-lg border-l-4 border-slate-400">
                <h4 className="font-bold mb-1">é€šä¿—ç†è§£ï¼š</h4>
                <p className="text-sm mb-2">
                    <strong>Warmup (çƒ­èº«)ï¼š</strong> å°±åƒå¼€è½¦ä¸Šé«˜é€Ÿã€‚ä½ ä¸èƒ½ä¸€å¯åŠ¨å°±æŒ‚äº”æ¡£ï¼ˆå¤§å­¦ä¹ ç‡ï¼‰ï¼Œé‚£æ ·å®¹æ˜“ç†„ç«ï¼ˆæ¢¯åº¦å‘æ•£ï¼‰ã€‚ä½ éœ€è¦æ…¢æ…¢åŠ é€Ÿï¼ˆçº¿æ€§å¢åŠ ï¼‰ï¼Œç­‰è½¦è·‘é¡ºäº†å†ç¨³å®šé€Ÿåº¦å·¡èˆªã€‚
                </p>
                <p className="text-sm">
                   <strong>æ®‹å·®è¿æ¥ï¼š</strong> å°±åƒç»™ä¿¡æ¯ä¼ è¾¾å¼€äº†ä¸€æ¡â€œå¿«é€Ÿé€šé“â€ã€‚å³ä½¿ç½‘ç»œå¾ˆæ·±ï¼Œä¿¡æ¯ä¹Ÿå¯ä»¥é€šè¿‡è¿™æ¡é€šé“ç›´æ¥ä¼ åˆ°æ·±å±‚ï¼Œé˜²æ­¢åœ¨å±‚å±‚ä¼ é€’ä¸­ä¸¢å¤±ï¼ˆæ¢¯åº¦æ¶ˆå¤±ï¼‰ã€‚
                </p>
            </div>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch5',
    title: '5. å®éªŒç»“æœä¸å½±å“',
    description: 'å®ƒçœŸçš„æœ‰æ•ˆå—ï¼Ÿ',
    sections: [
      {
        id: '5-1',
        title: 'å¤šç»´åº¦æ€§èƒ½åˆ†æ',
        content: (
          <div>
             <p className="mb-4">
                Transformer åœ¨ WMT 2014 è‹±å¾·å’Œè‹±æ³•ç¿»è¯‘ä»»åŠ¡ä¸Šå‡è¾¾åˆ°äº†å½“æ—¶çš„ SOTA (State-of-the-art) æ°´å¹³ï¼Œä¸”è®­ç»ƒæˆæœ¬å¤§å¹…é™ä½ã€‚
            </p>
            <div className="h-64 w-full mb-6">
              <ResponsiveContainer width="100%" height="100%">
                <BarChart data={perfData} layout="vertical" margin={{ top: 5, right: 30, left: 40, bottom: 5 }}>
                  <CartesianGrid strokeDasharray="3 3" />
                  <XAxis type="number" domain={[20, 30]} />
                  <YAxis dataKey="name" type="category" width={100} style={{fontSize: '12px'}} />
                  <Tooltip />
                  <Legend />
                  <Bar dataKey="bleu" name="BLEU åˆ†æ•°" fill="#0ea5e9" />
                </BarChart>
              </ResponsiveContainer>
              <p className="text-center text-xs text-slate-500 mt-2">BLEU åˆ†æ•°å¯¹æ¯”ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰</p>
            </div>
            
             <div className="grid grid-cols-2 gap-4">
                <div className="p-4 border rounded bg-white">
                    <h4 className="font-bold text-green-600">è®­ç»ƒæ•ˆç‡ (Efficiency)</h4>
                    <p className="text-sm mt-1">
                        å¾—ç›Šäºå¹¶è¡Œè®¡ç®—ï¼ŒTransformer (Big) åœ¨ 8 å¼  GPU ä¸Šä»…è®­ç»ƒäº† <strong>3.5 å¤©</strong>ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œä¹‹å‰çš„ LSTM æ¨¡å‹å¾€å¾€éœ€è¦è®­ç»ƒæ•°å‘¨ã€‚
                    </p>
                </div>
                <div className="p-4 border rounded bg-white">
                    <h4 className="font-bold text-purple-600">æ³›åŒ–èƒ½åŠ› (Generalization)</h4>
                    <p className="text-sm mt-1">
                        è®ºæ–‡ä¸ä»…æµ‹è¯•äº†ç¿»è¯‘ï¼Œè¿˜è¯æ˜äº†è¯¥æ¨¡å‹å¯ä»¥å¾ˆå¥½åœ°è¿ç§»åˆ°å…¶ä»–ä»»åŠ¡ï¼Œå¦‚æˆåˆ†å¥æ³•åˆ†æ (Constituency Parsing)ï¼Œä¸”å‡ ä¹ä¸éœ€è¦è°ƒæ•´è¶…å‚æ•°ã€‚
                    </p>
                </div>
            </div>
          </div>
        )
      }
    ]
  },
  {
    id: 'ch6',
    title: '6. èµ„æºä¸ä»£ç ',
    description: 'æ·±å…¥ç ”ç©¶',
    sections: [
      {
        id: '6-1',
        title: 'å®˜æ–¹å®ç°ä¸æºç ',
        content: (
          <div>
            <p className="mb-4">
                Transformer çš„åŸå§‹ä»£ç å‘å¸ƒåœ¨ Google çš„ Tensor2Tensor åº“ä¸­ã€‚ä»¥ä¸‹æ˜¯é‡è¦èµ„æºçš„é“¾æ¥ï¼š
            </p>
            <ul className="space-y-4">
                <li>
                    <a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noreferrer" className="flex items-center gap-2 p-4 border rounded hover:bg-slate-50 transition group">
                        <span className="text-2xl">ğŸ“„</span>
                        <div>
                            <div className="font-bold text-brand-600 group-hover:underline">é˜…è¯»åŸå§‹è®ºæ–‡ (ArXiv)</div>
                            <div className="text-sm text-slate-500">Attention Is All You Need (Vaswani et al., 2017)</div>
                        </div>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/tensorflow/tensor2tensor" target="_blank" rel="noreferrer" className="flex items-center gap-2 p-4 border rounded hover:bg-slate-50 transition group">
                        <span className="text-2xl">ğŸ’»</span>
                        <div>
                            <div className="font-bold text-slate-800 group-hover:underline">Tensor2Tensor (åŸå§‹ä»£ç )</div>
                            <div className="text-sm text-slate-500">è®ºæ–‡ä½¿ç”¨çš„å®˜æ–¹ TensorFlow å®ç°ã€‚</div>
                        </div>
                    </a>
                </li>
                 <li>
                    <a href="https://github.com/pytorch/fairseq" target="_blank" rel="noreferrer" className="flex items-center gap-2 p-4 border rounded hover:bg-slate-50 transition group">
                        <span className="text-2xl">ğŸ”¥</span>
                        <div>
                            <div className="font-bold text-slate-800 group-hover:underline">PyTorch FairSeq</div>
                            <div className="text-sm text-slate-500">Facebook AI Research æ¨å‡ºçš„åºåˆ—å»ºæ¨¡å·¥å…·åŒ…ï¼ŒåŒ…å«é«˜è´¨é‡çš„ Transformer å®ç°ã€‚</div>
                        </div>
                    </a>
                </li>
            </ul>
          </div>
        )
      }
    ]
  }
];

export const getChapters = (lang: Language) => lang === 'zh' ? chaptersZh : chaptersEn;